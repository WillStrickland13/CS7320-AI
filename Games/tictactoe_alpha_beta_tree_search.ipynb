{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Search: Solving Tic-Tac-Toe with Minimax Search and Alpha-Beta Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "Multiplayer games can be implemented as:\n",
    "1. Nondeterministic actions: The opponent is seen as part of an environment with nondeterministic actions. Non-determinism is the result of the unknown opponent's moves. \n",
    "2. __Optimal Decisions:__ Minimax search (search complete game tree) and alpha-beta pruning.\n",
    "3. Heuristic Alpha-Beta Tree Search: Cut off tree search and use heuristic to estimate state value. \n",
    "4. Monte Carlo Tree search: Simulate playouts to estimate state value. \n",
    "\n",
    "Here we will implement search for Tic-Tac-Toe (see [rules](https://en.wikipedia.org/wiki/Tic-tac-toe)). The game is a __zero-sum game__: Win by x results in +1, win by o in -1 and a tie has a value of 0. Max plays x and tries to maximize the outcome while Min plays o and tries to minimize the outcome.   \n",
    "\n",
    "We will implement\n",
    "* __minimax search__, and\n",
    "* __minimax search with alpha-beta pruning.__ \n",
    "\n",
    "The search time (number if nodes explored) could be further improved by \n",
    "* __move ordering__ (search moves first that have performed well in previous games), \n",
    "* __heuristic alpha-beta tree search__ (cut off search and use heuristic evaluation function to approximate utility), \n",
    "* __forward pruning__ (prune moves that appear poor), and\n",
    "* __table lookups__ (for openings and end game).\n",
    "\n",
    "The algorithms search the game tree and we could return a conditional plan (or partial plan if cut offs are used), but the implementation here only identifies and returns the optimal next move."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The board\n",
    "\n",
    "I represent the board as a vector of length 9. The values are `' ', 'x', 'o'`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def empty_board():\n",
    "    return [' '] * 9\n",
    "\n",
    "board = empty_board()\n",
    "display(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' ' ' ' ' ']\n",
      " [' ' ' ' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "\n",
      "Add some x's\n",
      "[['x' ' ' ' ']\n",
      " ['x' ' ' ' ']\n",
      " ['x' ' ' ' ']]\n"
     ]
    }
   ],
   "source": [
    "def show_board(board):\n",
    "    \"\"\"display the board\"\"\"\n",
    "    b = np.array(board).reshape((3,3))\n",
    "    print(b)\n",
    "\n",
    "board = empty_board()\n",
    "show_board(board)    \n",
    "\n",
    "print()\n",
    "print(\"Add some x's\")\n",
    "board[0] = 'x'; board[3] = 'x'; board[6] = 'x';  \n",
    "show_board(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['x' ' ' ' ']\n",
      " ['x' ' ' ' ']\n",
      " ['x' ' ' ' ']]\n",
      "Win? x\n",
      "\n",
      "[[' ' ' ' ' ']\n",
      " [' ' ' ' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "Win? n\n"
     ]
    }
   ],
   "source": [
    "def check_win(board):\n",
    "    \"\"\"check the board and return one of x, o, d (draw), or n (for next move)\"\"\"\n",
    "\n",
    "    board = np.array(board).reshape((3,3))  \n",
    "    diagonals = np.array([[board[i][i] for i in range(len(board))], \n",
    "                          [board[i][len(board)-i-1] for i in range(len(board))]])\n",
    "    \n",
    "    for a_board in [board, np.transpose(board), diagonals]:\n",
    "        for row in a_board:\n",
    "            if len(set(row)) == 1 and row[0] != ' ':\n",
    "                return row[0]\n",
    "\n",
    "    # check for draw\n",
    "    if(np.sum(board == ' ') < 1):\n",
    "        return 'd'\n",
    "    \n",
    "    return 'n'\n",
    "\n",
    "show_board(board)\n",
    "print('Win? ' + check_win(board))\n",
    "\n",
    "print()\n",
    "show_board(empty_board())\n",
    "print('Win? ' + check_win(empty_board()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['x' ' ' ' ']\n",
      " ['x' ' ' ' ']\n",
      " ['x' ' ' ' ']]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[1, 2, 4, 5, 7, 8]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_actions(board):\n",
    "    \"\"\"return possible actions as a vector ot indices\"\"\"\n",
    "    return np.where(np.array(board) == ' ')[0].tolist()\n",
    "\n",
    "    # randomize the action order\n",
    "    #actions = np.where(np.array(board) == ' ')[0]\n",
    "    #np.random.shuffle(actions)\n",
    "    #return actions.tolist()\n",
    "\n",
    "\n",
    "show_board(board)\n",
    "get_actions(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other(player): \n",
    "    if player == 'x': return 'o'\n",
    "    else: return 'x'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive DFS algorithm for Minimax Search\n",
    "\n",
    "See AIMA page 150. \n",
    "\n",
    "Calculates the minimax value for each state (i.e., the utility for Max assuming that both players play optimally from the current state to the end of the game).\n",
    "\n",
    "The implementation is for player 'x' (Max) and returns a the optimal next move (leads to the state with the largest minimax value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' ' ' ' ' ']\n",
      " [' ' ' ' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "\n",
      "State for placing an x at position 4:\n",
      "[[' ' ' ' ' ']\n",
      " [' ' 'x' ' ']\n",
      " [' ' ' ' ' ']]\n"
     ]
    }
   ],
   "source": [
    "def result(state, player, action):\n",
    "    \"\"\"Add move to the board.\"\"\"\n",
    "    \n",
    "    state = state.copy()\n",
    "    if(state[action] != ' '):\n",
    "        print(\"Error: Illegal move!\")\n",
    "    state[action] = player\n",
    "  \n",
    "    return state\n",
    "\n",
    "show_board(empty_board())\n",
    "\n",
    "print()\n",
    "print(\"State for placing an x at position 4:\")\n",
    "show_board(result(empty_board(), 'x', 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return utility for a state. Terminal states return the utility for Max as `+1`, -`1` or `0`. Non-terminal state have no utility and return `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "-1\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def utility(state, player = 'x'):\n",
    "    \"\"\"check is a state is terminal and return the utility if it is. None means not a terminal mode.\"\"\"\n",
    "    goal = check_win(state)        \n",
    "    if goal == player: return +1 \n",
    "    if goal == 'd': return 0  \n",
    "    if goal == other(player): return -1  # loss is failure\n",
    "    return None # continue\n",
    "\n",
    "print(utility(['x'] * 9))\n",
    "print(utility(['o'] * 9))\n",
    "print(utility(empty_board()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if a state is a terminal state. __Note:__ I use `utility(state, player) is not None` to identify terminal states in the code below to avoid calling `check_win` twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def is_terminal(state): \n",
    "    \"\"\"check is a state is a terminal state\"\"\"\n",
    "    return check_win(state) != \"n\"\n",
    "\n",
    "print(is_terminal(['x'] * 9))\n",
    "print(is_terminal(empty_board()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DEBUG = 1 # 1 ... count nodes, 2 ... debug each node\n",
    "COUNT = 0\n",
    "\n",
    "def minimax_search(board, player = 'x'):\n",
    "    \"\"\"start the search.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT = 0\n",
    "    \n",
    "    value, move = max_value(board, player)\n",
    "    \n",
    "    if DEBUG >= 1: print(f\"Number of nodes searched: {COUNT}\") \n",
    " \n",
    "    return { \"move\": move, \"value\": value}\n",
    "\n",
    "def max_value(state, player):\n",
    "    \"\"\"player's best move.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # return utility of state if it is a terminal state\n",
    "    v = utility(state, player)\n",
    "    if DEBUG >= 2: print(\"max in: \" + str(state) + str([v]) ) \n",
    "    if v is not None: return v, None\n",
    "        \n",
    "    v, move = -math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, return move with the largest value\n",
    "    for a in get_actions(state):\n",
    "        v2, a2 = min_value(result(state, player, a), player)\n",
    "        if v2 > v:\n",
    "            v, move = v2, a\n",
    "    \n",
    "    if DEBUG >= 2: print(\"max out: \" + str(state) + str([v, move]) ) \n",
    "    return v, move\n",
    "\n",
    "def min_value(state, player):\n",
    "    \"\"\"opponent's best response.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # return utility of state if it is a terminal state\n",
    "    v = utility(state, player)\n",
    "    if DEBUG >= 2: print(\"min in: \" + str(state) + str([v]) ) \n",
    "    if v is not None: return v, None\n",
    "    \n",
    "    v, move = +math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, return move with the smallest value\n",
    "    for a in get_actions(state):\n",
    "        v2, a2 = max_value(result(state, other(player), a), player)\n",
    "        if v2 < v:\n",
    "            v, move = v2, a\n",
    "    \n",
    "    if DEBUG >= 2: print(\"min out: \" + str(state) + str([v, move]) ) \n",
    "    return v, move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notes:__\n",
    "\n",
    "* The code check the available actions in order and picks the first one with the largest/smallest value. There are many ties. We could randomize `get_action()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Tests\n",
    "\n",
    "### x is about to win (choose 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board:\n",
      "[['x' 'o' ' ']\n",
      " ['o' 'x' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "\n",
      "Number of nodes searched: 190\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'move': 2, 'value': 1}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.2 ms, sys: 43.1 ms, total: 53.4 ms\n",
      "Wall time: 6.07 ms\n"
     ]
    }
   ],
   "source": [
    "board = empty_board() \n",
    "board[0] = 'x'\n",
    "board[1] = 'o'\n",
    "board[3] = 'o'\n",
    "board[4] = 'x'\n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "print()\n",
    "%time display(minimax_search(board))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The code does not pick the the shortest path to a win! Discounting the utility could help.\n",
    "\n",
    "### x can draw if it chooses 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board:\n",
      "[['x' 'o' 'x']\n",
      " [' ' 'o' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "\n",
      "Number of nodes searched: 206\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'move': 7, 'value': 0}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.6 ms, sys: 81.5 ms, total: 94 ms\n",
      "Wall time: 11.2 ms\n"
     ]
    }
   ],
   "source": [
    "board = empty_board() \n",
    "board[0] = 'x'\n",
    "board[1] = 'o'\n",
    "board[2] = 'x'\n",
    "board[4] = 'o'\n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "print()\n",
    "%time display(minimax_search(board))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### o is about to win no matter what x does\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board:\n",
      "[['o' 'o' ' ']\n",
      " ['o' 'x' ' ']\n",
      " [' ' ' ' 'x']]\n",
      "\n",
      "Number of nodes searched: 33\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'move': 2, 'value': -1}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.51 ms, sys: 20.4 ms, total: 24.9 ms\n",
      "Wall time: 3.06 ms\n"
     ]
    }
   ],
   "source": [
    "board = empty_board() \n",
    "board[0] = 'o'\n",
    "board[1] = 'o'\n",
    "board[3] = 'o'\n",
    "board[4] = 'x'\n",
    "board[8] = 'x'\n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "print()\n",
    "%time display(minimax_search(board))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### o went first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board:\n",
      "[[' ' ' ' ' ']\n",
      " [' ' 'o' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'move': 8, 'value': 0}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.06 s, sys: 7.24 ms, total: 1.07 s\n",
      "Wall time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "board = empty_board() \n",
    "board[4] = 'o'\n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "print()\n",
    "%time display(minimax_search(board))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empty board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board:\n",
      "[[' ' ' ' ' ']\n",
      " [' ' ' ' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'move': 4, 'value': 0}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 s, sys: 31.8 ms, total: 10.4 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "board = empty_board() \n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "\n",
    "print()\n",
    "%time display(minimax_search(board))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ Starting with an empty board searched the complete game tree and takes a while. The number of nodes above is the actual size of the complete game tree. A table with know 'openings' (e.g., place x in a corner, o chooses the center, etc.) would be helpful to speed things up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive DFS algorithm for Minimax Search with Alpha-Beta Pruning\n",
    "\n",
    "See AIMA page 154. \n",
    "\n",
    "Adds alpha-beta pruning to minimax search. Alpha and beta are used to maintain bounds on the minimax value of a node in the form `[alpha, beta]`. alpha means that the value is at least that high and beta means that the actual value is at most that high. Subtrees below a node that are worse than the currently known bound do not need to be further explored and can be pruned. Max uses alpha and Min uses beta for pruning.\n",
    "\n",
    "The implementation is for player 'x' returns a the optimal next move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DEBUG = 1 # 1 ... count nodes, 2 ... debug each node\n",
    "COUNT = 0\n",
    "\n",
    "def alpha_beta_search(board, player = 'x'):\n",
    "    \"\"\"start the search.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT = 0\n",
    "    \n",
    "    value, move = max_value_ab(board, player, -math.inf, +math.inf)\n",
    "    \n",
    "    if DEBUG >= 1: print(f\"Number of nodes searched: {COUNT}\") \n",
    "    \n",
    "    return { \"move\": move, \"value\": value }\n",
    "\n",
    "def max_value_ab(state, player, alpha, beta):\n",
    "    \"\"\"player's best move.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "       \n",
    "    # return utility of state is a terminal state\n",
    "    v = utility(state, player)\n",
    "    if DEBUG >= 2: print(\"max: \" + str(state) + str([alpha, beta, v]) ) \n",
    "    if v is not None: return v, None\n",
    "        \n",
    "    v, move = -math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update alpha and return move with the largest value\n",
    "    for a in get_actions(state):\n",
    "        v2, a2 = min_value_ab(result(state, player, a), player, alpha, beta)\n",
    "        if v2 > v:\n",
    "            v, move = v2, a\n",
    "            alpha = max(alpha, v)\n",
    "        if v >= beta: return v, move\n",
    "    \n",
    "    return v, move\n",
    "\n",
    "def min_value_ab(state, player, alpha, beta):\n",
    "    \"\"\"opponent's best response.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # return utility of state is a terminal state\n",
    "    v = utility(state, player)\n",
    "    if DEBUG >= 2: print(\"min: \" + str(state) + str([alpha, beta, v]) ) \n",
    "    if v is not None: return v, None\n",
    "    \n",
    "    v, move = +math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update beta and return move with the smallest value\n",
    "    for a in get_actions(state):\n",
    "        v2, a2 = max_value_ab(result(state, other(player), a), player, alpha, beta)\n",
    "        if v2 < v:\n",
    "            v, move = v2, a\n",
    "            beta = min(beta, v)\n",
    "        if v <= alpha: return v, move\n",
    "    \n",
    "    return v, move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notes:__\n",
    "\n",
    "* The code check the available actions in order and picks the first one with the largest/smallest value. There are many ties. We could randomize `get_action()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Tests\n",
    "\n",
    "### x is about to win (play 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board:\n",
      "[['x' 'o' ' ']\n",
      " ['o' 'x' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "\n",
      "Number of nodes searched: 61\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'move': 2, 'value': 1}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.12 ms, sys: 593 µs, total: 2.71 ms\n",
      "Wall time: 2.22 ms\n"
     ]
    }
   ],
   "source": [
    "board = empty_board() \n",
    "board[0] = 'x'\n",
    "board[1] = 'o'\n",
    "board[3] = 'o'\n",
    "board[4] = 'x'\n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "print()\n",
    "%time display(alpha_beta_search(board))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code does not pick the the shortest path to a win! Discounting could help.\n",
    "\n",
    "### x can draw if it chooses 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board:\n",
      "[['x' 'o' 'x']\n",
      " [' ' 'o' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "\n",
      "Number of nodes searched: 101\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'move': 7, 'value': 0}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.94 ms, sys: 561 µs, total: 3.5 ms\n",
      "Wall time: 3.09 ms\n"
     ]
    }
   ],
   "source": [
    "board = empty_board() \n",
    "board[0] = 'x'\n",
    "board[1] = 'o'\n",
    "board[2] = 'x'\n",
    "board[4] = 'o'\n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "print()\n",
    "%time display(alpha_beta_search(board))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### o is about to win no matter what x does\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board:\n",
      "[['o' 'o' ' ']\n",
      " ['o' 'x' ' ']\n",
      " [' ' ' ' 'x']]\n",
      "\n",
      "Number of nodes searched: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'move': 2, 'value': -1}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.17 ms, sys: 680 µs, total: 1.85 ms\n",
      "Wall time: 1.35 ms\n"
     ]
    }
   ],
   "source": [
    "board = empty_board() \n",
    "board[0] = 'o'\n",
    "board[1] = 'o'\n",
    "board[3] = 'o'\n",
    "board[4] = 'x'\n",
    "board[8] = 'x'\n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "print()\n",
    "%time display(alpha_beta_search(board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### o went first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board:\n",
      "[[' ' ' ' ' ']\n",
      " [' ' 'o' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "\n",
      "Number of nodes searched: 2316\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'move': 0, 'value': 0}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.7 ms, sys: 1.1 ms, total: 44.8 ms\n",
      "Wall time: 44 ms\n"
     ]
    }
   ],
   "source": [
    "board = empty_board() \n",
    "board[4] = 'o'\n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "\n",
    "print()\n",
    "%time display(alpha_beta_search(board))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empty board: Only a draw an be guaranteed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board:\n",
      "[[' ' ' ' ' ']\n",
      " [' ' ' ' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "\n",
      "Number of nodes searched: 18297\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'move': 0, 'value': 0}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 346 ms, sys: 4.7 ms, total: 350 ms\n",
      "Wall time: 349 ms\n"
     ]
    }
   ],
   "source": [
    "board = empty_board() \n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "\n",
    "print()\n",
    "%time display(alpha_beta_search(board))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Alpha-Beta search expands fewer nodes and is much faster than minimax search. \n",
    "\n",
    "## Move ordering\n",
    "\n",
    "Smart move reordering can make alpha-beta pruning more effective. I think the center `[4]` and corners `[0, 2, 6, 8]` are good. I implement move reordering in the `get_action()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' ' ' ' ' ']\n",
      " [' ' ' ' ' ']\n",
      " [' ' ' ' ' ']]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[4, 8, 6, 2, 0, 7, 5, 3, 1]"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_actions(board):\n",
    "    \"\"\"return possible actions as a vector ot indices\"\"\"\n",
    "    actions = np.where(np.array(board) == ' ')[0].tolist()\n",
    "\n",
    "    priority = [1,0,1,\n",
    "                0,2,0,\n",
    "                1,0,1]\n",
    "    priority = [priority[i] for i in actions]\n",
    "    \n",
    "    actions =[a for _,a in sorted(zip(priority,actions), reverse=True)]\n",
    "    \n",
    "    return actions\n",
    "\n",
    "board = empty_board()   \n",
    "show_board(board)\n",
    "get_actions(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empty board: Only a draw an be guaranteed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board:\n",
      "[[' ' ' ' ' ']\n",
      " [' ' ' ' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "\n",
      "Number of nodes searched: 7275\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'move': 4, 'value': 0}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 145 ms, sys: 3.24 ms, total: 149 ms\n",
      "Wall time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "board = empty_board() \n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "\n",
    "print()\n",
    "%time display(alpha_beta_search(board))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ Compare to the number of nodes searched without move reordering (right above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "\n",
    "### Baseline: Randomized Player\n",
    "\n",
    "A completely randomized player agent should be a weak baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' ' ' ' ' ']\n",
      " [' ' ' ' ' ']\n",
      " [' ' ' ' ' ']]\n"
     ]
    },
    {
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.14 ms, sys: 1.3 ms, total: 2.44 ms\n",
      "Wall time: 3.69 ms\n"
     ]
    }
   ],
   "source": [
    "def random_player(board, player = None):\n",
    "    \"\"\"Simple player that chooses a random empy square. player is unused\"\"\"\n",
    "    return np.random.choice(get_actions(board))\n",
    "\n",
    "show_board(board)\n",
    "%time display(random_player(board))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Environment\n",
    "\n",
    "Implement the environment that calls the agent. The percept is the board and the action is move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_player(player, x, o):\n",
    "    \"\"\"Switch player symbol and agent function between turns.\n",
    "    player is a player symbol and x and o are the players' agent functions.\"\"\"\n",
    "    if player == 'x':\n",
    "        return 'o', o\n",
    "    else:\n",
    "        return 'x', x\n",
    "\n",
    "def play(x, o, N = 100):\n",
    "    \"\"\"Play N games. x and o are the players' agent functions.\"\"\"\n",
    "    results = {'x': 0, 'o': 0, 'd': 0}\n",
    "    for i in range(N):\n",
    "        board = empty_board()\n",
    "        player, fun = 'x', x\n",
    "        \n",
    "        while True:\n",
    "            a = fun(board, player)\n",
    "            board = result(board, player, a)\n",
    "            \n",
    "            win = check_win(board)\n",
    "            if win != 'n':\n",
    "                results[win] += 1\n",
    "                break\n",
    "            \n",
    "            player, fun = switch_player(player, x, o)   \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random vs. Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'x': 574, 'o': 307, 'd': 119}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 233 ms, sys: 29.7 ms, total: 263 ms\n",
      "Wall time: 239 ms\n"
     ]
    }
   ],
   "source": [
    "%time display(play(random_player, random_player, N = 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimax with Alpha-Beta Pruning vs. Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha-beta vs. random:\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'x': 97, 'o': 0, 'd': 3}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 s, sys: 144 ms, total: 16.2 s\n",
      "Wall time: 16.2 s\n",
      "\n",
      "random vs. alpha-beta\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m<timed eval>:1\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n",
      "Input \u001B[0;32mIn [28]\u001B[0m, in \u001B[0;36mplay\u001B[0;34m(x, o, N)\u001B[0m\n\u001B[1;32m     14\u001B[0m player, fun \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m'\u001B[39m, x\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m---> 17\u001B[0m     a \u001B[38;5;241m=\u001B[39m \u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mboard\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplayer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m     board \u001B[38;5;241m=\u001B[39m result(board, player, a)\n\u001B[1;32m     20\u001B[0m     win \u001B[38;5;241m=\u001B[39m check_win(board)\n",
      "Input \u001B[0;32mIn [30]\u001B[0m, in \u001B[0;36malpha_beta_player\u001B[0;34m(board, player)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21malpha_beta_player\u001B[39m(board, player \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m----> 4\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malpha_beta_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mboard\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplayer\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmove\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "Input \u001B[0;32mIn [18]\u001B[0m, in \u001B[0;36malpha_beta_search\u001B[0;34m(board, player)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mglobal\u001B[39;00m DEBUG, COUNT\n\u001B[1;32m      8\u001B[0m COUNT \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m---> 10\u001B[0m value, move \u001B[38;5;241m=\u001B[39m \u001B[43mmax_value_ab\u001B[49m\u001B[43m(\u001B[49m\u001B[43mboard\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplayer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43mmath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mmath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m DEBUG \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m: \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of nodes searched: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mCOUNT\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m) \n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m { \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmove\u001B[39m\u001B[38;5;124m\"\u001B[39m: move, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m\"\u001B[39m: value }\n",
      "Input \u001B[0;32mIn [18]\u001B[0m, in \u001B[0;36mmax_value_ab\u001B[0;34m(state, player, alpha, beta)\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# check all possible actions in the state, update alpha and return move with the largest value\u001B[39;00m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m get_actions(state):\n\u001B[0;32m---> 30\u001B[0m     v2, a2 \u001B[38;5;241m=\u001B[39m \u001B[43mmin_value_ab\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplayer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplayer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeta\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m v2 \u001B[38;5;241m>\u001B[39m v:\n\u001B[1;32m     32\u001B[0m         v, move \u001B[38;5;241m=\u001B[39m v2, a\n",
      "Input \u001B[0;32mIn [18]\u001B[0m, in \u001B[0;36mmin_value_ab\u001B[0;34m(state, player, alpha, beta)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;66;03m# check all possible actions in the state, update beta and return move with the smallest value\u001B[39;00m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m get_actions(state):\n\u001B[0;32m---> 52\u001B[0m     v2, a2 \u001B[38;5;241m=\u001B[39m \u001B[43mmax_value_ab\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m(\u001B[49m\u001B[43mplayer\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplayer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeta\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m v2 \u001B[38;5;241m<\u001B[39m v:\n\u001B[1;32m     54\u001B[0m         v, move \u001B[38;5;241m=\u001B[39m v2, a\n",
      "Input \u001B[0;32mIn [18]\u001B[0m, in \u001B[0;36mmax_value_ab\u001B[0;34m(state, player, alpha, beta)\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# check all possible actions in the state, update alpha and return move with the largest value\u001B[39;00m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m get_actions(state):\n\u001B[0;32m---> 30\u001B[0m     v2, a2 \u001B[38;5;241m=\u001B[39m \u001B[43mmin_value_ab\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplayer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplayer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeta\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m v2 \u001B[38;5;241m>\u001B[39m v:\n\u001B[1;32m     32\u001B[0m         v, move \u001B[38;5;241m=\u001B[39m v2, a\n",
      "Input \u001B[0;32mIn [18]\u001B[0m, in \u001B[0;36mmin_value_ab\u001B[0;34m(state, player, alpha, beta)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;66;03m# check all possible actions in the state, update beta and return move with the smallest value\u001B[39;00m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m get_actions(state):\n\u001B[0;32m---> 52\u001B[0m     v2, a2 \u001B[38;5;241m=\u001B[39m \u001B[43mmax_value_ab\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m(\u001B[49m\u001B[43mplayer\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplayer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeta\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m v2 \u001B[38;5;241m<\u001B[39m v:\n\u001B[1;32m     54\u001B[0m         v, move \u001B[38;5;241m=\u001B[39m v2, a\n",
      "Input \u001B[0;32mIn [18]\u001B[0m, in \u001B[0;36mmax_value_ab\u001B[0;34m(state, player, alpha, beta)\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# check all possible actions in the state, update alpha and return move with the largest value\u001B[39;00m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m get_actions(state):\n\u001B[0;32m---> 30\u001B[0m     v2, a2 \u001B[38;5;241m=\u001B[39m \u001B[43mmin_value_ab\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplayer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplayer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeta\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m v2 \u001B[38;5;241m>\u001B[39m v:\n\u001B[1;32m     32\u001B[0m         v, move \u001B[38;5;241m=\u001B[39m v2, a\n",
      "Input \u001B[0;32mIn [18]\u001B[0m, in \u001B[0;36mmin_value_ab\u001B[0;34m(state, player, alpha, beta)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;66;03m# check all possible actions in the state, update beta and return move with the smallest value\u001B[39;00m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m get_actions(state):\n\u001B[0;32m---> 52\u001B[0m     v2, a2 \u001B[38;5;241m=\u001B[39m \u001B[43mmax_value_ab\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m(\u001B[49m\u001B[43mplayer\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplayer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeta\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m v2 \u001B[38;5;241m<\u001B[39m v:\n\u001B[1;32m     54\u001B[0m         v, move \u001B[38;5;241m=\u001B[39m v2, a\n",
      "Input \u001B[0;32mIn [18]\u001B[0m, in \u001B[0;36mmax_value_ab\u001B[0;34m(state, player, alpha, beta)\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# check all possible actions in the state, update alpha and return move with the largest value\u001B[39;00m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m get_actions(state):\n\u001B[0;32m---> 30\u001B[0m     v2, a2 \u001B[38;5;241m=\u001B[39m \u001B[43mmin_value_ab\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplayer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplayer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeta\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m v2 \u001B[38;5;241m>\u001B[39m v:\n\u001B[1;32m     32\u001B[0m         v, move \u001B[38;5;241m=\u001B[39m v2, a\n",
      "Input \u001B[0;32mIn [18]\u001B[0m, in \u001B[0;36mmin_value_ab\u001B[0;34m(state, player, alpha, beta)\u001B[0m\n\u001B[1;32m     48\u001B[0m v, move \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m+\u001B[39mmath\u001B[38;5;241m.\u001B[39minf, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;66;03m# check all possible actions in the state, update beta and return move with the smallest value\u001B[39;00m\n\u001B[0;32m---> 51\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m \u001B[43mget_actions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m     52\u001B[0m     v2, a2 \u001B[38;5;241m=\u001B[39m max_value_ab(result(state, other(player), a), player, alpha, beta)\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m v2 \u001B[38;5;241m<\u001B[39m v:\n",
      "Input \u001B[0;32mIn [25]\u001B[0m, in \u001B[0;36mget_actions\u001B[0;34m(board)\u001B[0m\n\u001B[1;32m      5\u001B[0m priority \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m      6\u001B[0m             \u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m      7\u001B[0m             \u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m      8\u001B[0m priority \u001B[38;5;241m=\u001B[39m [priority[i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m actions]\n\u001B[0;32m---> 10\u001B[0m actions \u001B[38;5;241m=\u001B[39m[a \u001B[38;5;28;01mfor\u001B[39;00m _,a \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(\u001B[38;5;28;43mzip\u001B[39;49m(priority,actions), reverse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)]\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m actions\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "DEBUG = 0\n",
    "\n",
    "def alpha_beta_player(board, player = 'x'):\n",
    "    return alpha_beta_search(board, player)[\"move\"]\n",
    "\n",
    "print(\"alpha-beta vs. random:\")\n",
    "%time display(play(alpha_beta_player, random_player))\n",
    "\n",
    "print()\n",
    "print(\"random vs. alpha-beta\")\n",
    "%time display(play(random_player, alpha_beta_player))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}