{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Search: Playing Dots and Boxes\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Total Points: Undegraduates 100, graduate students 110\n",
    "\n",
    "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "You will implement different versions of agents that play the game Dots and Boxes:\n",
    "\n",
    "> \"Dots and Boxes is a pencil-and-paper game for two players. The game starts with an empty grid of dots. Usually two players take turns adding a single horizontal or vertical line between two unjoined adjacent dots. A player who completes the fourth side of a 1x1 box earns one point and takes another turn. A point is typically recorded by placing a mark that identifies the player in the box, such as an initial. The game ends when no more lines can be placed. The winner is the player with the most points. The board may be of any size grid.\" (see [Dots and Boxes on Wikipedia](https://en.wikipedia.org/wiki/Dots_and_Boxes))\n",
    "\n",
    "You can play Dots and Boxes [here](https://www.math.ucla.edu/~tom/Games/dots&boxes.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Defining the Search Problem [10 point]\n",
    "\n",
    "Define the components of the search problem associated with this game:\n",
    "\n",
    "* Initial state\n",
    "* Actions\n",
    "* Transition model\n",
    "* Test for the terminal state\n",
    "* Utility for terminal states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the state space? Give an estimate and explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the game tree that minimax search will go through? Give an estimate and explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Game Environment and Random Agent [30 point]\n",
    "\n",
    "You need to think about a data structure to represent the board meaning he placed lines and who finished what box. There are many options. Let's represent the board using a simple dictionary where `n` and `m` represents the number of dots horizontaly and vertically, respectively. Everybody needs to use the same representation so we can let agents play against each other later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = {\n",
    "    'n': 4,  ### hoizontal dots\n",
    "    'm': 4   ### vertical dots\n",
    "}\n",
    "\n",
    "def draw_line(board, orientation, row, col):\n",
    "    \"\"\"\n",
    "    Place a line on an exiting board.\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    board: dict\n",
    "        the board\n",
    "    orientation: str\n",
    "        either 'h' or 'v' for horizontal or vertical\n",
    "    row, col: int\n",
    "        index of the starting dot for the line (starting with 0)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if orientation not in ['h', 'v']:\n",
    "        return False\n",
    "        \n",
    "    if row < 0 or col < 0:\n",
    "        return False\n",
    "        \n",
    "    if row >= board['n'] + (orientation == 'v') or col >= board['m'] + (orientation == 'h'):\n",
    "        return False\n",
    "        \n",
    "    if (orientation, row, col) in board:\n",
    "        return False\n",
    "            \n",
    "    board[(orientation, row, col)] = True\n",
    "    return True\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to display the board. **Bonus point: Post your visualization code with an example output to the discussion board. The best visualization will earn you bonus participation points in this class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code/ answer goes here.\n",
    "#https://stackoverflow.com/questions/35109590/how-to-graph-nodes-on-a-grid-in-networkx\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "edge_colors = ['blue', 'red']\n",
    "edgeLabels = {}\n",
    "# functions  to create empty visualization\n",
    "def drawBoard(G,edgeLabels):\n",
    "\n",
    "    colors = nx.get_edge_attributes(G,'color').values()\n",
    "    labels = nx.get_edge_attributes(G,'label').values()\n",
    "    pos = {(x,y):(y,-x) for x,y in G.nodes()}\n",
    "    nx.draw(G, pos=pos,\n",
    "        node_color='lightgreen',\n",
    "        edge_color=colors,\n",
    "        width=8,\n",
    "        with_labels=True,\n",
    "        node_size=600)\n",
    "    nx.draw_networkx_edge_labels(G, pos, edgeLabels)\n",
    "\n",
    "def createEmptyBoard(G,edgeLabels):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    for edge in G.edges():\n",
    "        G.remove_edge(*edge)\n",
    "    # Set margins for the axes so that nodes aren't clipped\n",
    "    #drawBoard(G,edgeLabels)\n",
    "\n",
    "def addEdge(G,board, x,y, orientation,player,edgeLabels):\n",
    "    #set the colors of the edges\n",
    "    color=edge_colors[player]\n",
    "    label=player\n",
    "    draw_line(board, orientation, x,y)\n",
    "\n",
    "    #add the edge to the graph\n",
    "    if orientation == 'h':\n",
    "        G.add_edge((x,y), (x,y+1), color=color, label=label)\n",
    "        edgeLabels.update({((x,y),(x,y+1)):player})\n",
    "    else:\n",
    "        G.add_edge((x,y), (x+1,y), color=color, label=label)\n",
    "        edgeLabels.update({((x,y),(x+1,y)):player})\n",
    "    #drawBoard(G,edgeLabels)\n",
    "    return board\n",
    "\n",
    "def removeEdge(G,board, x,y, orientation,edgeLabels):\n",
    "    del board[(orientation, x,y)]\n",
    "    #add the edge to the graph\n",
    "    if orientation == 'h':\n",
    "        G.remove_edge((x,y), (x,y+1))\n",
    "        edgeLabels.update({((x,y),(x,y+1)):\"\"})\n",
    "    else:\n",
    "        G.remove_edge((x,y), (x+1,y))\n",
    "        edgeLabels.update({((x,y),(x+1,y)):\"\"})\n",
    "    #drawBoard(G,edgeLabels)\n",
    "    return board\n",
    "# G = nx.grid_2d_graph(board['n'], board['m'])\n",
    "# createEmptyBoard(G,edgeLabels)\n",
    "# addEdge(G,board, 0,0, 'h',1,edgeLabels)\n",
    "# removeEdge(G,board, 0,0, 'h',edgeLabels)\n",
    "# drawBoard(G,edgeLabels)\n",
    "# addEdge(G, 0,0, 'v',1)\n",
    "#\n",
    "#\n",
    "# addEdge(G, 0,1, 'v',1)\n",
    "# addEdge(G, 1,0, 'h',0)\n",
    "#\n",
    "# addEdge(G,2,2, 'h',0)\n",
    "# addEdge(G,2,2, 'v',1)\n",
    "# addEdge(G,2,3, 'v',1)\n",
    "# addEdge(G,3,2, 'h',0)\n",
    "# print(board)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement helper functions for:\n",
    "\n",
    "* The transition model $result(s, a)$.\n",
    "* The utility function $utility(s)$.\n",
    "* Check for terminal states $terminal(s)$.\n",
    "* A check for available actions in each state $actions(s)$.\n",
    "\n",
    "Make sure that all these functions work with boards of different sizes (number of columns and rows as stored in the board)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here.\n",
    "def result(board, draw_line):\n",
    "    return board\n",
    "\n",
    "\n",
    "\n",
    "def utility(board):\n",
    "    #check who has more boxes and award that player a point\n",
    "    player1=0\n",
    "    player0=0\n",
    "    #print(board)\n",
    "    for i in range(board['n']-1):\n",
    "        for j in range(board['m']-1):\n",
    "            #if the all sides of the box exist and are true\n",
    "            if (('h', i, j) in board and board['h',i,j]==True)\\\n",
    "                    and (('h', i+1, j) in board and board['h',i+1,j]==True) \\\n",
    "                    and (('v', i, j) in board and board['v',i,j]==True)\\\n",
    "                    and (('v', i, j+1) in board and board['v',i,j+1]==True):\n",
    "\n",
    "                # then determine which player completed the box by checking which was most recently\n",
    "                # added to the list of moves\n",
    "                mostRecentMove = list(board.keys()).index(('h', i, j))\n",
    "                if(list(board.keys()).index(('h', i+1, j)) > mostRecentMove):\n",
    "                    mostRecentMove= list(board.keys()).index(('h', i+1, j))\n",
    "                if(list(board.keys()).index(('v', i, j+1)) > mostRecentMove):\n",
    "                    mostRecentMove= list(board.keys()).index(('v', i, j+1))\n",
    "                if(list(board.keys()).index(('v', i, j)) > mostRecentMove):\n",
    "                    mostRecentMove= list(board.keys()).index(('v', i, j))\n",
    "\n",
    "                #set the most recent move to the most recent move index\n",
    "                value_at_index=list(board.keys())[mostRecentMove]\n",
    "\n",
    "                #determine the the player whos number is on the edge that completed the box\n",
    "                if(value_at_index[0]=='h'):\n",
    "                    player = (edgeLabels[(value_at_index[1],value_at_index[2]),(value_at_index[1],value_at_index[2]+1)])\n",
    "                if(value_at_index[0]=='v'):\n",
    "                    player = (edgeLabels[(value_at_index[1],value_at_index[2]),(value_at_index[1]+1,value_at_index[2])])\n",
    "\n",
    "                #increment the player that completed the box\n",
    "                if(player==1):\n",
    "                    player1+=1\n",
    "                else:\n",
    "                    player0+=1\n",
    "    #if player1 has more boxes, return 1\n",
    "    if player1>player0:\n",
    "        return 1\n",
    "    #if player0 has more boxes, return 0\n",
    "    elif player0>player1:\n",
    "        return 0\n",
    "    #if they are equal, return -1\n",
    "    else:\n",
    "        return -1\n",
    "def actions(board):\n",
    "    #initialize list of actions to none\n",
    "    acts=[]\n",
    "\n",
    "    #check if there are any available actions\n",
    "    for i in range (board['n']-1):\n",
    "        for j in range (board['m']-1):\n",
    "            orientation = 'h'\n",
    "            if (orientation, i, j) not in board:\n",
    "                acts.append((orientation, i, j))\n",
    "            orientation = 'v'\n",
    "            if (orientation, i, j) not in board:\n",
    "                acts.append((orientation, i, j))\n",
    "\n",
    "    #Add bottom and right side of board to possible actions\n",
    "    for i in range(board['n']-1):\n",
    "        if(\"v\",i,board['m']-1) not in board:\n",
    "            acts.append((\"v\",i,board['m']-1))\n",
    "    for i in range(board['m']-1):\n",
    "        if(\"h\",board['n']-1,i) not in board:\n",
    "            acts.append((\"h\",board['n']-1,i))\n",
    "    return acts\n",
    "\n",
    "\n",
    "\n",
    "def terminal(board):\n",
    "    #if there are no more actions, then the game is over\n",
    "    if actions(board)==[]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#print(actions(board))\n",
    "\n",
    "\n",
    "\n",
    "#utility(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement an agent that plays randomly. Make sure the agent function receives as the percept the board and returns a valid action. Use an agent function definition with the following signature (arguments):\n",
    "\n",
    "`def random_player(board, player = None): ...`\n",
    "\n",
    "The argument `player` is used for agents that do not store what side they are playing. The value passed on bt yhe environment should be 1 ot -1 for playerred and yellow, respectively.  See [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x432 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "import random\n",
    "\n",
    "def random_player(board, player,edgeLabels):\n",
    "    #load all possible actions into a list\n",
    "    acts=actions(board)\n",
    "\n",
    "    #randomly choose an action from the list\n",
    "    act=acts[random.randint(0,len(acts)-1)]\n",
    "\n",
    "    #execute and add the random edge to the board\n",
    "    addEdge(G2,board, act[1],act[2], act[0],player,edgeLabels)\n",
    "\n",
    "\n",
    "#reset the colors and labels on the visualization\n",
    "edge_colors = ['blue', 'red']\n",
    "edgeLabels = {}\n",
    "\n",
    "#set the board height and width\n",
    "board2 = {\n",
    "    'n': 6,  ### hoizontal dots\n",
    "    'm': 6   ### vertical dots\n",
    "}\n",
    "\n",
    "#create empty visualization\n",
    "G2 = nx.grid_2d_graph(board2['n'], board2['m'])\n",
    "createEmptyBoard(G2,edgeLabels)\n",
    "\n",
    "#loop while not terminal\n",
    "while not terminal(board2):\n",
    "    random_player(board2, 1,edgeLabels)\n",
    "    if not terminal(board2):\n",
    "        random_player(board2, 0,edgeLabels)\n",
    "\n",
    "#print the winner\n",
    "utility(board2)\n",
    "\n",
    "#clear the visualization\n",
    "G2.clear()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let two random agents play against each other 1000 times. Look at the [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) to see how the environment uses the agent functions to play against each other.\n",
    "\n",
    "How often does each player win? Is the result expected?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* After testing on various board sizes, I found that with a small board, with 9 possible boxes, the player who goes first won around 90% of the time. However, with a larger board, with 36 possible boxes, each player wins about 50% of the time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1 wins  552\n",
      "Player 0 wins  448\n",
      "Ties  0\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "def play(limit):\n",
    "    player1wins=0\n",
    "    player0wins=0\n",
    "    ties=0\n",
    "    for i in range(limit):\n",
    "        edgeLabels = {}\n",
    "        board2 = {\n",
    "            'n': 6,  ### hoizontal dots\n",
    "            'm': 6   ### vertical dots\n",
    "        }\n",
    "        G2 = nx.grid_2d_graph(board2['n'], board2['m'])\n",
    "        createEmptyBoard(G2,edgeLabels)\n",
    "\n",
    "        #loop until terminal state\n",
    "        while not terminal(board2):\n",
    "            random_player(board2, 1,edgeLabels)\n",
    "            if not terminal(board2):\n",
    "                random_player(board2, 0,edgeLabels)\n",
    "        #if winner is player 1, increment player1wins\n",
    "        if utility(board2)==1:\n",
    "            player1wins+=1\n",
    "        #if winner is player 0, increment player0wins\n",
    "        elif utility(board2)==0:\n",
    "            player0wins+=1\n",
    "        #if utility is tie, increment ties\n",
    "        else:\n",
    "            ties+=1\n",
    "\n",
    "        #clear graph for next iteration\n",
    "        G2.clear()\n",
    "\n",
    "        #close the graph\n",
    "        plt.close()\n",
    "\n",
    "    #Print the results\n",
    "    print(\"Player 1 wins \",player1wins)\n",
    "    print(\"Player 0 wins \",player0wins)\n",
    "    print(\"Ties \",ties)\n",
    "\n",
    "\n",
    "play(1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Minimax Search with Alpha-Beta Pruning [30 points]\n",
    "\n",
    "### Implement the search starting.\n",
    "\n",
    "Implement the search starting from a given board and specifying the player and put it into an agent function.\n",
    "You can use code from the [tic-tac-toe example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_alpha_beta_tree_search.ipynb).\n",
    "\n",
    "__Notes:__ \n",
    "* Make sure that all your agent functions have a signature consistent with the random agent above.\n",
    "* The search space for larger board may be too large. You can experiment with smaller boards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1, -1)\n",
      "{'n': 4, 'm': 4}\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x432 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "def minimax(G,board, depth, isMax,edgeLabels):\n",
    "    score = utility(board)\n",
    "\n",
    "    # If Maximizer has won the game return his/her\n",
    "    # evaluated score\n",
    "    if (score == 1) :\n",
    "        print(\"Maximizer has won the game\")\n",
    "        return score\n",
    "\n",
    "    # If Minimizer has won the game return his/her\n",
    "    # evaluated score\n",
    "    if (score == 0) :\n",
    "        print(\"Minimizer has won the game\")\n",
    "        return score\n",
    "\n",
    "    # If there are no more moves and no winner then\n",
    "    # it is a tie\n",
    "    if (utility(board) == -1) :\n",
    "        print(\"Game is a tie\")\n",
    "        return 0\n",
    "\n",
    "    # If this maximizer's move\n",
    "    if (isMax) :\n",
    "        best = -1000\n",
    "\n",
    "        # Traverse all cells\n",
    "        for i in board['n']-1 :\n",
    "            for j in board['m']-1 :\n",
    "                for c in range(2):\n",
    "                # Check if cell is empty\n",
    "                    if c == 1:\n",
    "                        orientation = 'v'\n",
    "                    else:\n",
    "                        orientation = 'h'\n",
    "\n",
    "\n",
    "                    if (orientation, i, j) not in board:\n",
    "                        addEdge(G,board,i,j,orientation,1,edgeLabels)\n",
    "\n",
    "                    # Call minimax recursively and choose\n",
    "                    # the maximum value\n",
    "                        best = max( best, minimax(board,\n",
    "                                              depth + 1,\n",
    "                                              not isMax) )\n",
    "\n",
    "                    # Undo the move\n",
    "                        removeEdge(G,board,i,j,orientation,edgeLabels)\n",
    "        return best\n",
    "\n",
    "    # If this minimizer's move\n",
    "    else :\n",
    "        best = 1000\n",
    "\n",
    "        # Traverse all cells\n",
    "        for i in range(board['n']-1) :\n",
    "            for j in range(board['m']-1) :\n",
    "                for c in range(2):\n",
    "                # Check if cell is empty\n",
    "                    if c == 1:\n",
    "                        orientation = 'v'\n",
    "                    else:\n",
    "                        orientation = 'h'\n",
    "\n",
    "\n",
    "                    if (orientation, i, j) not in board:\n",
    "                        addEdge(G,board,i,j,orientation,1,edgeLabels)\n",
    "\n",
    "                    # Call minimax recursively and choose\n",
    "                    # the maximum value\n",
    "                        best = min( best, minimax(board,\n",
    "                                              depth + 1,\n",
    "                                              not isMax) )\n",
    "\n",
    "                    # Undo the move\n",
    "                        removeEdge(G,board,i,j,orientation,edgeLabels)\n",
    "        return best\n",
    "\n",
    "# This will return the best possible move for the player\n",
    "def findBestMove(board,G) :\n",
    "    bestVal = -1000\n",
    "    bestMove = (-1, -1)\n",
    "\n",
    "    # Traverse all cells, evaluate minimax function for\n",
    "    # all empty cells. And return the cell with optimal\n",
    "    # value.\n",
    "\n",
    "    for i in range(board['n']-1) :\n",
    "        for j in range(board['m']-1) :\n",
    "                for c in range(2):\n",
    "                # Check if cell is empty\n",
    "                    if c == 1:\n",
    "                        orientation = 'v'\n",
    "                    else:\n",
    "                        orientation = 'h'\n",
    "\n",
    "\n",
    "                    if (orientation, i, j) not in board:\n",
    "                        addEdge(G,board,i,j,orientation,1,edgeLabels)\n",
    "\n",
    "                        moveVal = minimax(G,board,0,False,edgeLabels)\n",
    "\n",
    "                        removeEdge(G,board,i,j,orientation,edgeLabels)\n",
    "\n",
    "                        if(moveVal > bestVal) :\n",
    "                            bestMove = (orientation,i, j)\n",
    "                            bestVal = moveVal\n",
    "\n",
    "    print(\"The value of the best Move is :\", bestVal)\n",
    "\n",
    "    print(bestMove)\n",
    "    return bestMove\n",
    "\n",
    "edgeLabels = {}\n",
    "board = {\n",
    "    'n': 4,  ### hoizontal dots\n",
    "    'm': 4   ### vertical dots\n",
    "}\n",
    "G = nx.grid_2d_graph(board['n'], board['m'])\n",
    "createEmptyBoard(G,edgeLabels)\n",
    "# while not terminal(board):\n",
    "#     bestMove = findBestMove(board,G)\n",
    "#     addEdge(G,board,bestMove[1],bestMove[2],bestMove[0],1,edgeLabels)\n",
    "#     if not terminal(board):\n",
    "#         bestMove = findBestMove(board,G)\n",
    "#         addEdge(G,board,bestMove[1],bestMove[2],bestMove[0],0,edgeLabels)\n",
    "print(bestMove)\n",
    "drawBoard(G,edgeLabels)\n",
    "print(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with some manually created boards (at least 5) to check if the agent spots winning opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board make the board larger. What is the largest board you can solve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move ordering\n",
    "\n",
    "Starting the search with better moves will increase the efficiency of alpha-beta pruning. Describe and implement a simple move ordering strategy. Make a table that shows how the ordering strategies influence the time it takes to make a move?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first few moves\n",
    "\n",
    "Start with an empty board. This is the worst case scenario for minimax search with alpha-beta pruning since it needs solve all possible games that can be played (minus some pruning) before making the decision. What can you do? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let the Minimax Search agent play a random agent on a small board. Analyze wins, losses and draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Heuristic Alpha-Beta Tree Search [30 points] \n",
    "\n",
    "### Heuristic evaluation function\n",
    "\n",
    "Define and implement a heuristic evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutting off search \n",
    "\n",
    "Modify your Minimax Search with Alpha-Beta Pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with the same manually created boards as above to check if the agent spots winning opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let two heuristic search agents (different cutoff depth, different heuristic evaluation function) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tournament task [+1 to 5% bonus on your course grade; will be assigned separately]\n",
    "\n",
    "Find another student and let your best agent play against the other student's best player. You are allowed to use any improvements you like as long as you code it yourself. We will set up a class tournament on Canvas. This tournament will continue after the submission deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate student advanced task: Pure Monte Carlo Search and Best First Move [10 point]\n",
    "\n",
    "__Undergraduate students:__ This is a bonus task you can attempt if you like [+5 Bonus point].\n",
    "\n",
    "### Pure Monte Carlo Search\n",
    "\n",
    "Implement Pure Monte Carlo Search (see [tic-tac-toe-example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_pure_monte_carlo_search.ipynb)) and investigate how this search performs on the test boards that you have used above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best First Move\n",
    "\n",
    "How would you determine what the best first move for a standard board ($5 \\times 5$) is? You can use Pure Monte Carlo Search or any algorithms that you have implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}